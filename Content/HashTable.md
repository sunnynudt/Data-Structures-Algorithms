# 散列表(哈希表、HashTable)

核心思想：散列表用的是数组支持按照下标随机访问的时候，时间复杂度是 `O(1)`的特性。我们通过散列函数把元素的键值映射为下标，然后将数据存储在数组中对应下标的位置。当我们按照键值查询元素时，我们用同样的散列函数，将键值转化数组下标，从对应的数组下标的位置取出数据。所以，散列表其实就是数组的一种扩展，由数组演化而来，没有数组就不会有散列表。

## 1. 散列函数

可以定义成`hash(key)`，其中`key`表示元素的键值，`hash(key)`的值表示经过散列函数计算得到的散列值。

散列函数设计的基本要求：

1. 散列函数计算得到的散列值是一个**非负整数**。因为数组下标是从 0 开始的，所以散列函数生成的散列值也要是非负整数。
2. 如果`key1 == key2`，那么`hash(key1) == hash(key2)`；
3. 如果`key1 != key2`，那么`hash(key1) != hash(key2)`。这个要求看似合理，但是真实情况下难以实现，无法避免这种散列冲突。另外，因为数组的存储空间有限，也会加大散列冲突的概率。

## 2. 散列冲突

常用的解决散列冲突的解决方法有两类，开放寻址法和链表法。

### 1. 开放寻址法(open addressing)

核心思想：如果出现了散列冲突，就重新探测一个空间位置，将其插入。

(1) 线性探测(Linear Probing)

_插入数据_：当往散列表中插入数据时，如果某个数据经过散列函数散列之后，存储位置已经被占用了，就从当前位置开始，依次往后查找，看到是否有空闲位置，直到找到位置。 如果遍历到尾部，都没有找到空闲位置，则再从表头开始查找，直到找到空闲位置，将其插入到这个位置。

_查找元素_：类似插入过程，通过散列函数求出要查找元素的键值对应的散列值，然后比较数组中下标为散列值的元素和要查找的元素。如果相等，则说明就是我们要查找的元素；否则就顺序往后依次查找。如果遍历到尾部，还没有找到元素或空闲位置，则再从表头开始遍历，如果遍历到数组中的空闲位置，还没有找到，则说明查找的元素不在散列表中。

_删除操作_：兼顾上面查找元素的过程，可以将删除的元素，特殊标记为 deleted。当线性探测查找的时候，遇到标记为 deleted 的空间，并不是停下来，而是继续往下探测。

线性探测存在很大不足，最坏情况下，时间复杂度是`O(n)`。

（2）二次探测(Quadratic probing)
（3）双重散列(Double hashing)

`散列表的装载因子 = 填入表中的元素个数 / 散列表的长度`

装载因子越大，说明空闲位置越少，冲突越多，散列表的性能会下降。

### 2. 链表法(chaining)

链表法是一种更加常用的散列冲突解决办法，相比开放寻址法，更加简单。

![](/Content/Pic/散列表_链表法.jpg)

_插入操作_：只需要通过散列函数计算出对应的散列槽位，将其插入到对应的链表中即可，时间复杂度是`O(1)`。
_查找、删除操作_：时间复杂度和链表的长度 k 成正比，`O(k)`。对于散列比较均匀的散列函数来说，理论上，`k = n / m`，其中 n 表示散列表中的数据的个数，m 表示散列表中“槽”的个数。

## 3. 散列函数的设计

散列函数设计的好坏，决定了散列表冲突的概率大小，也直接决定了散列表的性能。

1. 散列函数的设计不能太复杂。

2. 散列函数生成的值要尽可能随机并且均匀分布。

### 1. 如何避免低效的扩容

为了解决一次性扩容耗时过多的情况，可以将扩容操作穿插在插入操作的过程中，分批完成。当装载因子触达阈值后，只申请新空间，并不将老的数据搬移到新列表中。

对于查询操作，为了兼容新、老散列中的数据，先从新散列表中查找，如果没有找到，再去老的散列表中查找。通过这样均摊的方法，将一次性扩容的代价，均摊到多次插入操作中，就避免了一次性扩容耗时过多的情况。这种实现方式下，任何情况下，插入一个数据的时间复杂度都是`O（1）`。

![](/Content/Pic/散列表_扩容.jpg)

### 2. 如何选择冲突解决方法

1. 开放寻址法

当数据量比较小、装载因子小的时候，适合采用开放寻址法。

2. 链表法

基于链表的散列冲突处理方法比较适合存储大对象、大数据的散列表，而且，比起开发寻址法，它更加灵活，支持更多的优化策略，比如用红黑树代替链表。
