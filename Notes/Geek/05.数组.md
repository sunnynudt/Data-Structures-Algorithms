### 数组：为什么很多编程语言中数组都从 0 开始编号？

数组，不仅仅是一种编程语言中的数据类型，还是一种最基础的数据结构。在大部分编程中，数组都是从 0 开始编号的，但是，**为什么数组要从 0 开始编号，而不是从 1 开始呢？**

#### 1. 如何实现随机访问？

**数组(Array)是一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据**。这里，有几个关键词。

-   线性表(Linear List)，顾名思义，线性表就是数据排成像一条线一样的结构。每个线性表上的数据最多只有前和后两个方向。除了数组，链表、队列、栈等也是[线性表](/MindMap/Geek/5.1线性表.jpg)结构。而与它相对立的概念是[非线性表](/MindMap/Geek/5.1线性表.jpg)，比如二叉树、堆和图等。之所以叫非线性表，是因为，在非线性表中，数据之间并不是简单地前后关系。

-   连续的内存空间和相同类型的数据。

正式因为这两个限制，它才有了堪称“杀手锏”的特性：“随机访问”。但是有利就有弊，这两个限制也让数组的很多操作变得非常低效，比如要想在数组中删除、插入一个数据，为了保证连续性，就需要做大量的数据搬移工作。

那数组如何根据下标随机访问数组元素呢？

拿一个长度为 10 的`int`类型的数组`int[] a = new int[10]`来举例。在[画图](/MindMap/Geek/5.3数组的内存地址表示.jpg)中，计算机给数组 a[10]，分配了一块连续内存空间 1000~1039，其中，内存块的首地址为`base_address = 1000`。我们知道，计算机会给每个内存单元分配一个地址，计算机通过地址来访问内存中的数据。当计算机需要随机访问数组中的某个元素的时候，它会首先根据寻址公式`a[i]_address = base_address + i * data_type_size`，计算出该元素存储的内存地址，其中 data_type_size，表示数组中每个元素的大小。我们这个例子中，数组中存储的是 int 类型数据，所以 data_type_size 就为 4 个字节。

在这里需要纠正一个“错误”。在我面试时候，常常会问数组和链表的区别，很多人都回答说，“链表适合插入、删除，时间复杂度为 O(1)；数组适合查找，查找时间复杂度为 O(1)”。实际上，这种表示不准确的。数组是适合查找，但是查找的时间复杂度并不是 O(1)。即便是排好序的数组，用二分查找，时间复杂度也是`O(logn)`。所以，正确的表述应该是，数组支持随机访问，根据下标随机访问的时间复杂度为 O(1)。

#### 2. 低效的“插入”和“删除”

数组为了保持内存数据的连续性，会导致插入、删除操作比较低效。

##### 插入操作

假设数组的长度为 n，现在，如果我们需要将一个数据插入到数组中的第 k 个位置。为了把第 k 个位置的腾出来，给新来的数据，需要将第 k~n 这部分的元素都顺序地往后挪一位。那插入的时间复杂度为多少呢？

如果在数组的末尾插入元素，那就不需要移动数据了，这时的时间复杂度为 O(1)。但是如果在数组的开头插入元素，那所有的数据都需要依次往后移动一位，所以最坏时间复杂度为 O(n)。因为我们在每个位置插入元素的概率都是一样的，所以平均情况时间复杂度为(O(1)+O(2)+...+O(n))/n=O((1+2+...+n)/n)=O(n)。

如果数组中数据是有序的，我们在某个位置插入一个新的元素时，就必须按照刚才的方法搬移 k 之后的数据。但是，如果数组中存储的数据并没有任何规律，数组只是被当做一个存储数据的集合时。在这种情况下，如果要将某个数组插入到第 k 个位置，为了避免大规模的数据搬移，还有一个简单办法是，直接将第 k 位的数据搬移到数组元素的最后，把新的元素直接放入第 k 个位置。

举个[例子](/MindMap/Geek/5.4数组的插入操作.jpg)，假设数组 a[10]中存储如下 5 个元素：a,b,c,d,e。

我们现在需要将元素 x 插入到第 3 个位置。我们只需要将 c 放到 a[5]，将 a[2]复制为 x 即可。最后，数组中的元素为：a,b,x,d,e,c。

利用这种处理技巧，在特定场景下，在第 k 个位置插入一个元素的时间复杂度就会将为 O(1)。这个思想在快排中会用到。

##### 删除操作

跟插入数据类似，如果我们要删除第 k 个位置的数据，为了内存的连续性，也需要搬移数据，不然中间就会出现空洞，内存就不连续了。

和插入类似，如果删除数组末尾的数据，则最好情况时间复杂度为 O(1)；如果删除开头的数据，则最坏情况时间复杂度为 O(n)；平均情况时间复杂度也为 O(n)。

实际上，在某些特殊场景下，我们并不一定非得追求数组中数据的连续性。如果我们将多次删除操作集中在一起执行，删除的效率是不是会提高很多呢？

我们继续看[例子](/MindMap/Geek/5.5数组的删除操作.jpg)。数组中 a[10]中存储了 8 个元素：a,b,c,d,e,f,g,h。现在，我们要依次删除 a,b,c 三个元素。

为了避免 d,e,f,g,h 这几个数据会被搬移三次，我们可以先记录下已经删除的数据。每次的删除操作并不是真正的搬移数据，只是记录数据已经被删除。当数组中没有更多空间存储数据时，我们再触发一次真正的删除操作，这样就大大减少了删除操作导致的数据搬移。

如果了解 JVM，就会发现，这就是 JVM 标记清除垃圾回收算法的核心思想。数据结构和算法的魅力最在于，很多时候并不是要去死记硬背某个数据结构或算法，而是要学习它背后的思想和处理技巧，这些东西才是最有价值的。

#### 警惕数组的越界访问问题

```c
// c语言代码
int main(int argc, char* argv[]){
 int i = 0;
 int arr[3] = {0};
 for(;i<=3;i++) {
     arr[i] = 0;
     printf("hello world\n")
 }
 return 0;
}
```

发现问题了吗？这段代码的运行结果并非是打印三行‘hello world’，而是会无限打印'hello world'，why？

因为，数组大小为 3，a[0]、a[1]、a[2]，而我们的代码因书写错误，导致 for 循环的结束条件错写为 i<=3，而不是 i<3，所以当 i=3 时，数组 a[3]访问越界了。

我们知道，在 C 语言中，只要不是访问受限的内存，所有的内存空间都是可以自由访问的。根据我们前面讲的数组寻址公式，a[3]也会被定位到某块不属于数组的内存地址上，而这个地址更好是存储变量 i 的内存地址，那么 a[3]=0 就相当于 i=0，所以会导致代码无限循环。

数组越界在 C 语言中是一种未决行为，并没有规定数据访问越界时编译器应该如何处理。因为，_访问数组的本质就是访问一段连续内存_，只要数组通过偏移计算得到的内存是可用的，那么程序就可能不会报任何错误。

这种情况下，一般都会出现莫名其妙的逻辑错误，就像刚才举得例子一样，debug 难度非常大。而且，很多计算机病毒也正是利用了代码中的数组越界可以访问非法地址的漏洞，来攻击系统，所以写代码的时候一定要警惕数组越界。

但是并非所有语言都像 C 语言一样，把数组越界检查的工作让程序员来做，像 Java 本身就会做越界检查。

#### 容器是否完全替代数组？

#### 解答“在大多数编程语言中，数组要从 0 开始编号，而不是从 1 开始”

从数组存储的内存模型上看，“下标”最确切的定义应该是“偏移(offset)”。如果用 a 来表示数组的首地址，a[0]就是偏移为 0 的位置，也就是首地址，a[k]就是偏移 k 个 type_size 的位置，所以计算 a[k]的内存地址只需要用这个公式：

`a[k]_address = base_address + k * type_size`

但是，如果数组从 1 开始计数，那我们计算数组元素 a[k]的内存地址就会变为：

`a[k]_address = base_address + (k-1)*type_size`

对比两个公式，不难发现，从 1 开始编号，每次随机访问数组都多了一次减法运算，对于 CPU 来说，就是多了一次减法指令。

数组作为非常基础的数据结构，通过下标随机访问数组元素又是其非常基础的编程操作，效率的优化就要尽可能做到极致。所以为了减少一次减法操作，数组选择了从 0 开始编号，而不是从 1 开始。

但是上述解析都不是压倒性的证明，说数组起始编号非 0 开始不可。个人觉得最主要的原因可能是历史原因。

C 语言设计者用 0 开始计数数组下标，之后的 Java，JavaScript 等高级语言都效仿了 C 语言，沿用了从 0 开始计数的习惯。实际上，很多语言也不是从 0 开始计算，比如 matlab，甚至 python 还可以负数下标。
