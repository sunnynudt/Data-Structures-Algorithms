### 几种常见时间复杂度实例分析

虽然代码千差万别，但是常见的复杂度量级并不多。下述复杂级量级几乎涵盖了今后可以接触的所有代码的复杂度量级。

```
复杂度量级（按数量级递增）
1. 常量阶 O(1)
2. 对数阶 O(logn)
3. 线性阶 O(n)
4. 线性对数阶 O(nlogn)
5. 平方阶 O(n^2)、立方阶 O(n^3)...k次方阶O(n^k)
6. 指数阶 O(2^n)
7. 阶乘阶 O(n!)
```

对于刚罗列的复杂度量级，可以粗略的分为两类，`多项式量级`和`非多项式量级`。其中，非多项式量级只有两个：`O(2^n)`和`O(n!)`。

我们把时间复杂度为非多项式量级的算法问题叫做`NP(Non-Deterministic Polynomial, 非确定多项式)问题`。

当数据规模`n`越来越大时，非多项式量级算法的执行时间会急剧增加，求解问题的执行时间会无限增长。所以，非多项式时间复杂度的算法其实是非常低效的算法。主要看下述常见的*多项式时间复杂度*。

#### 1. O(1)

首先必须明确一个概念，`O(1)`只是`常量级时间复杂度`的一种表示方法，并不是指只执行了一行代码。比如这段代码，即便有 3 行， 它的时间复杂度也是`O(1)`而不是`O(3)`。

```c
 int i = 8;
 int j = 6;
 int sum = i + j;
```

稍微总结一下，只要代码的执行时间不随着`n`的增大而增大，这样代码的时间复杂度我们都记作`O(1)`。或者说，**一般情况下，只要算法中不存在循环语句、递归语句，即使上千上万行的代码，其时间复杂度也是`O(1)`**。

#### 2. O(logn)、O(nlogn)

对数阶时间复杂度非常常见，同时也是最难分析的一种时间复杂度。

```c
 i=1;
 while (i <= n)  {
   i = i * 2;
 }
```

根据前面所述的复杂度分析法，第三行代码是循环执行次数最多的。所以，只要我们能计算出这行代码执行了多少次，就能知道整段代码的时间复杂度。

从代码中可以看出，变量 i 的值从 1 开始取，每循环一次就乘以 2。当大于`n`时，循环结束。 实际上，变量 i 的取值就是一个等比数列。如果我把它列出，就应该是这个样子：2<sup>0</sup> 2<sup>1</sup> 2<sup>2</sup> ... 2<sup>k</sup> ... 2<sup>x</sup>=n。

所以只要我们知道了`x`值是多少，就知道这行代码执行的次数了。2<sup>x</sup> = n 求解得到 x=log<sub>2</sub>n，所以这段代码的时间复杂度就是 O(log<sub>2</sub>n)。  
稍微改动一下代码  如下。

```c
 i=1;
 while (i <= n)  {
   i = i * 3;
 }
```

根据刚才的思路，这段代码的时间复杂度为 O(log<sub>3</sub>n)。

实际上，不管是以 2 为底、以 3 为底还是以 10 为底，我们可以把所有的对数阶的时间复杂度都记为 O(logn)。

因为对数之间  是可以互相转换的，log<sub>3</sub>n = log<sub>3</sub>2 \* log<sub>2</sub>n，所以 O(log<sub>3</sub>n) = O(C \* log<sub>2</sub>n)，其中 C = log<sub>3</sub>2 是一个常量。基于前面的一个理论：**在采用大 O 标记复杂度的时候，可以忽略系数，即 O(Cf(n)) = O(f(n))**。所以，O(log<sub>2</sub>n)就等于 O(log<sub>3</sub>n)。因此， 在对数阶时间复杂度的表示方法里，我们忽略对数的'底'，统一表示为 O(logn)。

如果理解了 O(logn)，那 O(nlogn)就很容易理解了。参考乘法法则，如果一段代码的时间复杂度为 O(log)，我们循环执行 n 遍，时间复杂度就是 O(nlogn)了。而且，O(nlogn)也是一种非常常见的算法时间复杂度。比如，归并排序、快速排序的时间复杂度都是 O(nlogn)。

#### 3. O(m+n)、O(m\*n)

与上述时间复杂度不同，此类代码的复杂度**由 2 个数据规模**来决定。

```c
int cal(int m, int n) {
  int sum_1 = 0;
  int i = 1;
  for (; i < m; ++i) {
    sum_1 = sum_1 + i;
  }

  int sum_2 = 0;
  int j = 1;
  for (; j < n; ++j) {
    sum_2 = sum_2 + j;
  }

  return sum_1 + sum_2;
}
```

从代码中可以看出，`m`和`n`是表示两个数据规模。我们无法实现评估`m、n`谁的量级大，所以我们在表示复杂度的时候，就不能简单地利用加法法则去省略掉其中的某一个。所以，上面代码的时间复杂度就是`O(m+n)`。

针对这种情况，原来的加法法则就不正确了。我们需要将加法规则改为：T1(m) + T2(n) = O(f(m) + g(n))。但是乘法法则继续有效：T1(m) \* T2(n) = O(f(m) \* f(n))。
