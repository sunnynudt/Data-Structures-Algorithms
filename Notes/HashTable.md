# 散列表(哈希表、HashTable)

核心思想：散列表用的是数组支持按照下标随机访问的时候，时间复杂度是 `O(1)`的特性。我们通过散列函数把元素的键值映射为下标，然后将数据存储在数组中对应下标的位置。当我们按照键值查询元素时，我们用同样的散列函数，将键值转化数组下标，从对应的数组下标的位置取出数据。所以，散列表其实就是数组的一种扩展，由数组演化而来，没有数组就不会有散列表。

## 1. 散列函数

可以定义成`hash(key)`，其中`key`表示元素的键值，`hash(key)`的值表示经过散列函数计算得到的散列值。

散列函数设计的基本要求：

1. 散列函数计算得到的散列值是一个**非负整数**。因为数组下标是从 0 开始的，所以散列函数生成的散列值也要是非负整数。
2. 如果`key1 == key2`，那么`hash(key1) == hash(key2)`；
3. 如果`key1 != key2`，那么`hash(key1) != hash(key2)`。这个要求看似合理，但是真实情况下难以实现，无法避免这种散列冲突。另外，因为数组的存储空间有限，也会加大散列冲突的概率。

## 2. 散列冲突

常用的解决散列冲突的解决方法有两类，开放寻址法和链表法。

### 1. 开放寻址法(open addressing)

核心思想：如果出现了散列冲突，就重新探测一个空间位置，将其插入。

(1) 线性探测(Linear Probing)

_插入数据_：当往散列表中插入数据时，如果某个数据经过散列函数散列之后，存储位置已经被占用了，就从当前位置开始，依次往后查找，看到是否有空闲位置，直到找到位置。 如果遍历到尾部，都没有找到空闲位置，则再从表头开始查找，直到找到空闲位置，将其插入到这个位置。

_查找元素_：类似插入过程，通过散列函数求出要查找元素的键值对应的散列值，然后比较数组中下标为散列值的元素和要查找的元素。如果相等，则说明就是我们要查找的元素；否则就顺序往后依次查找。如果遍历到尾部，还没有找到元素或空闲位置，则再从表头开始遍历，如果遍历到数组中的空闲位置，还没有找到，则说明查找的元素不在散列表中。

_删除操作_：兼顾上面查找元素的过程，可以将删除的元素，特殊标记为 deleted。当线性探测查找的时候，遇到标记为 deleted 的空间，并不是停下来，而是继续往下探测。

线性探测存在很大不足，最坏情况下，时间复杂度是`O(n)`。

（2）二次探测(Quadratic probing)
（3）双重散列(Double hashing)

`散列表的装载因子 = 填入表中的元素个数 / 散列表的长度`

装载因子越大，说明空闲位置越少，冲突越多，散列表的性能会下降。

### 2. 链表法(chaining)

链表法是一种更加常用的散列冲突解决办法，相比开放寻址法，更加简单。

![](/Assets/images/散列表_链表法.jpg)

_插入操作_：只需要通过散列函数计算出对应的散列槽位，将其插入到对应的链表中即可，时间复杂度是`O(1)`。
_查找、删除操作_：时间复杂度和链表的长度 k 成正比，`O(k)`。对于散列比较均匀的散列函数来说，理论上，`k = n / m`，其中 n 表示散列表中的数据的个数，m 表示散列表中“槽”的个数。

## 3. 散列函数的设计

散列函数设计的好坏，决定了散列表冲突的概率大小，也直接决定了散列表的性能。

1. 散列函数的设计不能太复杂。

2. 散列函数生成的值要尽可能随机并且均匀分布。

### 1. 如何避免低效的扩容

为了解决一次性扩容耗时过多的情况，可以将扩容操作穿插在插入操作的过程中，分批完成。当装载因子触达阈值后，只申请新空间，并不将老的数据搬移到新列表中。

对于查询操作，为了兼容新、老散列中的数据，先从新散列表中查找，如果没有找到，再去老的散列表中查找。通过这样均摊的方法，将一次性扩容的代价，均摊到多次插入操作中，就避免了一次性扩容耗时过多的情况。这种实现方式下，任何情况下，插入一个数据的时间复杂度都是`O（1）`。

![](/Assets/images/散列表_扩容.jpg)

### 2. 如何选择冲突解决方法

1. 开放寻址法

   当数据量比较小、装载因子小的时候，适合采用开放寻址法。

2. 链表法

   基于链表的散列冲突处理方法比较适合存储大对象、大数据的散列表，而且，比起开发寻址法，它更加灵活，支持更多的优化策略，比如用红黑树代替链表。

### 3. 工业级散列表的特征和设计实现

1. 特征

   - 支持快速的查询、插入、删除操作；
   - 内存占用合理，不能浪费过多的内存空间；
   - 性能稳定，极端情况下，散列表的性能也不会退化到无法接受的情况。

2. 设计思路

   - 设计一个合适的散列函数；
   - 定义装载因子阈值，并且设计动态扩容策略；
   - 选择合适的散列冲突解决方法。

## 4. 为什么散列表和链表经常会一起使用？

### 1. LRU 缓存淘汰算法

1.1 通过链表实现 LRU

维护一个按照访问时间从大到小有序排列的链表结构。因为缓存大小有限，当缓存空间不足，需要淘汰一个数据的时候，就直接将链表头部的结点删除。

当要缓存某个数据的时候，先在链表中查找这个数据。如果没有找到，则直接将数据放在链表的尾部；如果找到了，就把它移到到链表的尾部。因为查找数据需要遍历链表，所以单纯用链表实现的 LRU 缓存淘汰算法的时间复杂度很高，是`O(n)`。

一个缓存（cache）系统主要包含下面几个操作：

- 往缓存中添加一个数据
- 从缓存中删除一个数据
- 在缓存中查找一个数据

这三个操作里都要涉及到“查找”操作，如果单纯的采用链表的话，时间复杂度只能是 O(n)。

1.2 通过散列表和链表组合存储结构实现 LRU

如果我们将散列表和链表两种数据结构结合使用，可以将这三个操作的时间复杂度都降到`O(1)`。具体结构如下图。

![](/Assets/images/散列表_缓存淘汰算法.jpg)

使用双向链表存储数据，链表中的每个结点处理存储数据（data）、前驱指针（prev）、后继指针（next）之外，还新增一个特殊的字段 hnext。这个 hnext 有什么作用呢？

因为散列表是通过链表法解决散列冲突，所以每个结点会在两条链中。一个链是刚刚提到的双向链表，另一个链是散列表中的**拉链**。**前驱和后继指针是为了将结点串在双向链表中，hnext 指针是为了将结点串在散列表的拉链中。**。

上述三个操作过程涉及的查找操作都可以通过散列表来实现，时间复杂度是`O(1)`。其他的操作，比如删除头结点、链表尾部插入数据等，都可以在`O(1)`的时间复杂度内完成。所以上述三个操作的时间复杂度即为`O(1)`。

### 2. 小结

散列表这种数据结构虽然支持非常高效的数据插入、删除、查找操作，但是散列表中的数据都是通过散列函数打乱之后无规律存储的。也就是说，它无法支持按照某种顺序快速的遍历数据。如果希望按照顺序遍历散列表中的数据，那我们需要将散列表中的数据拷贝到数组中，然后再排序，再遍历。

因为散列表是动态数据结构，不停的有数据的插入、删除，所以每当我们希望按顺序遍历散列表中的数据的时候，都需要先排序，那效率势必很低。为了解决这个问题，我们将散列表和链表（跳表）结合在一起使用。

> 目前看，个人感觉主要的数据结构就是链表和数组。数组占据随机访问的优势，却有需要连续内存的缺点。链表具有可不连续存储的优势，但是访问查找是线性的。散列表和链表、跳表的混合使用，是为了结合数组和链表的优势，规避它们的不足。我们可以得出数据结构和算法的重要性排行榜：连续空间 > 时间 > 碎片空间。
